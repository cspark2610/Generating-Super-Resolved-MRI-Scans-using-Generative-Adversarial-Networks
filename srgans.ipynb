{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import cv2\n",
    "from skimage.transform import resize\n",
    "import skimage.io\n",
    "import scipy\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, Add\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.applications import VGG19\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import datetime\n",
    "import sys\n",
    "from tensorflow.python.client import device_lib \n",
    "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
    "%matplotlib inline\n",
    "\n",
    "print('Tensorflow Version: ', tf.__version__)\n",
    "print('Tensorflow built with Cuda: ', tf.test.is_built_with_cuda())\n",
    "print('Tensorflow built with GPU support: ', tf.test.is_built_with_gpu_support())\n",
    "print('GPU available: ', tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None), '\\n')\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory\n",
    "directory = 'SRGAN/non_demented'\n",
    "# Append list of image paths\n",
    "filepaths = []\n",
    "\n",
    "for dir_, _, files in os.walk(directory):\n",
    "    for fileName in files:\n",
    "        relDir = os.path.relpath(dir_, directory)\n",
    "        relFile = os.path.join(relDir, fileName)\n",
    "        filepaths.append(directory + \"/\" + relFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data Function\n",
    "def load_data(batch_size=1, is_testing=False):\n",
    "    \"\"\"\n",
    "    Outputs high-resolution image, low-resolution image\n",
    "    \"\"\"\n",
    "    data_type = \"train\" if not is_testing else \"test\"\n",
    "\n",
    "    batch_images = np.random.choice(filepaths, size=1)\n",
    "\n",
    "    imgs_hr = []\n",
    "    imgs_lr = []\n",
    "    for img_path in batch_images:\n",
    "        img = cv2.imread(img_path).astype(np.float)\n",
    "        h, w = (720, 720) # 256?\n",
    "        low_h, low_w = int(h / 4), int(w / 4)\n",
    "        img_hr = resize(img, (720, 720, 3))\n",
    "        img_lr = resize(img, (low_h, low_w, 3))\n",
    "\n",
    "        if not is_testing and np.random.random() < 0.5:\n",
    "            img_hr = np.fliplr(img_hr)\n",
    "            img_lr = np.fliplr(img_lr)\n",
    "\n",
    "        imgs_hr.append(img_hr)\n",
    "        imgs_lr.append(img_lr)\n",
    "\n",
    "    imgs_hr = np.array(imgs_hr) / 719.5 - 1.\n",
    "    imgs_lr = np.array(imgs_lr) / 719.5 - 1.\n",
    "\n",
    "    return imgs_hr, imgs_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Attributes\n",
    "dataset_name = 'non_demented'\n",
    "channels = 3                  # Channel\n",
    "lr_height = 180                # Low resolution height\n",
    "lr_width = 180                 # Low resolution width\n",
    "lr_shape = (lr_height, lr_width, channels)          # Low resolution shape\n",
    "hr_height = lr_height*4   # High resolution height\n",
    "hr_width = lr_width*4     # High resolution width\n",
    "hr_shape = (hr_height, hr_width, channels)          # High resolution shape\n",
    "n_residual_blocks = 16    # Number of residual blocks in the generator\n",
    "optimizer = Adam(0.0002, 0.5)     # Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct VGG19 Pre-Trained Model for Feature Extraction\n",
    "def build_vgg(hr_shape=hr_shape):\n",
    "    \"\"\"\n",
    "    Builds a pre-trained VGG19 model that outputs image features extracted  at the third block of the model\n",
    "    \"\"\"\n",
    "    vgg = VGG19(weights=\"imagenet\")\n",
    "    vgg.outputs = [vgg.layers[9].output]\n",
    "    img = Input(shape=hr_shape)\n",
    "\n",
    "    # Extract image features\n",
    "    img_features = vgg(img)\n",
    "\n",
    "    return Model(img, img_features)\n",
    "\n",
    "vgg = build_vgg(hr_shape)\n",
    "vgg.trainable = False\n",
    "vgg.compile(loss='mse',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure data loader\n",
    "\n",
    "patch = int(hr_height / 2**4)\n",
    "disc_patch = (patch, patch, 1)\n",
    "\n",
    "# Number of filters in the first layer of G and D\n",
    "gf = 64\n",
    "df = 64\n",
    "\n",
    "def build_discriminator(hr_shape=hr_shape, df=df):\n",
    "\n",
    "    def d_block(layer_input, filters, strides=1, bn=True):\n",
    "        \"\"\"\n",
    "        Discriminator layer\n",
    "        \"\"\"\n",
    "        d = Conv2D(filters, kernel_size=3, strides=strides, padding='same')(layer_input)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        if bn:\n",
    "            d = BatchNormalization(momentum=0.8)(d)\n",
    "        return d\n",
    "\n",
    "    # Input img\n",
    "    d0 = Input(shape=hr_shape)\n",
    "\n",
    "    d1 = d_block(d0, df, bn=False)\n",
    "    d2 = d_block(d1, df, strides=2)\n",
    "    d3 = d_block(d2, df*2)\n",
    "    d4 = d_block(d3, df*2, strides=2)\n",
    "    d5 = d_block(d4, df*4)\n",
    "    d6 = d_block(d5, df*4, strides=2)\n",
    "    d7 = d_block(d6, df*8)\n",
    "    d8 = d_block(d7, df*8, strides=2)\n",
    "\n",
    "    d9 = Dense(df*16)(d8)\n",
    "    d10 = LeakyReLU(alpha=0.2)(d9)\n",
    "    validity = Dense(1, activation='sigmoid')(d10)\n",
    "\n",
    "    return Model(d0, validity)\n",
    "\n",
    "# Build and compile the discriminator\n",
    "discriminator = build_discriminator(hr_shape, df)\n",
    "discriminator.compile(loss='mse',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(lr_shape=lr_shape, gf=gf, n_residual_blocks=n_residual_blocks, channels=channels):\n",
    "\n",
    "    def residual_block(layer_input, filters):\n",
    "        \"\"\"\n",
    "        Residual block described in paper\n",
    "        \"\"\"\n",
    "        d = Conv2D(filters, kernel_size=3, strides=1, padding='same')(layer_input)\n",
    "        d = Activation('relu')(d)\n",
    "        d = BatchNormalization(momentum=0.8)(d)\n",
    "        d = Conv2D(filters, kernel_size=3, strides=1, padding='same')(d)\n",
    "        d = BatchNormalization(momentum=0.8)(d)\n",
    "        d = Add()([d, layer_input])\n",
    "        return d\n",
    "\n",
    "    def deconv2d(layer_input):\n",
    "        \"\"\"\n",
    "        Layers used during upsampling\n",
    "        \"\"\"\n",
    "        u = UpSampling2D(size=2)(layer_input)\n",
    "        u = Conv2D(256, kernel_size=3, strides=1, padding='same')(u)\n",
    "        u = Activation('relu')(u)\n",
    "        return u\n",
    "\n",
    "    # Low resolution image input\n",
    "    img_lr = Input(shape=lr_shape)\n",
    "\n",
    "\n",
    "    c1 = Conv2D(64, kernel_size=9, strides=1, padding='same')(img_lr)\n",
    "    r = residual_block(c1, gf)\n",
    "    for _ in range(n_residual_blocks - 1):\n",
    "        r = residual_block(r, gf)\n",
    "    c2 = Conv2D(64, kernel_size=3, strides=1, padding='same')(r)\n",
    "    c2 = BatchNormalization(momentum=0.8)(c2)\n",
    "    c2 = Add()([c2, c1])\n",
    "\n",
    "    u1 = deconv2d(c2)\n",
    "    u2 = deconv2d(u1)\n",
    "\n",
    "    # Generate high resolution output\n",
    "    gen_hr = Conv2D(channels, kernel_size=9, strides=1, padding='same', activation='tanh')(u2)\n",
    "\n",
    "    return Model(img_lr, gen_hr)\n",
    "\n",
    "# Build the generator\n",
    "generator = build_generator(lr_shape, gf, n_residual_blocks, channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# High res and low res images\n",
    "img_hr = Input(shape=hr_shape)\n",
    "img_lr = Input(shape=lr_shape)\n",
    "\n",
    "# Generate high res version from low res\n",
    "fake_hr = generator(img_lr)\n",
    "\n",
    "# Extract image features of the generated img\n",
    "fake_features = vgg(fake_hr)\n",
    "\n",
    "discriminator.trainable = False\n",
    "\n",
    "# Discriminator determines validity of generated high res. images\n",
    "validity = discriminator(fake_hr)\n",
    "\n",
    "combined = Model([img_lr, img_hr], [validity, fake_features])\n",
    "combined.compile(loss=['binary_crossentropy', 'mse'],\n",
    "                      loss_weights=[1e-3, 1],\n",
    "                      optimizer=optimizer)\n",
    "\n",
    "        \n",
    "\n",
    "def sample_images(epoch, dataset_name=dataset_name):\n",
    "  \"\"\"\n",
    "  asdasd\n",
    "  \"\"\"\n",
    "\n",
    "  imgs_hr, imgs_lr = load_data(batch_size=2, is_testing=True)\n",
    "  fake_hr = generator.predict(imgs_lr)\n",
    "\n",
    "  # Rescale images 0 - 1\n",
    "  imgs_lr = (imgs_lr + 1)*511.5\n",
    "  fake_hr = (fake_hr + 1)*511.5\n",
    "  imgs_hr = (imgs_hr + 1)*511.5\n",
    "\n",
    "  # Save generated images and the high resolution originals\n",
    "  titles = ['Generated', 'Original']\n",
    "  fig, axs = plt.subplots(1, 2)\n",
    "  cnt = 0\n",
    "\n",
    "  for col, image in enumerate([fake_hr, imgs_hr]):\n",
    "    print(f'col: {col}')\n",
    "    axs[col].imshow(image[0].astype(int))\n",
    "    axs[col].set_title(titles[col])\n",
    "    axs[col].axis('off')\n",
    "    cnt += 1\n",
    "  fig.savefig(\"images/%s/720/%d.png\" % (dataset_name, epoch))\n",
    "  plt.close()\n",
    "\n",
    "  fig = plt.figure()\n",
    "  plt.imshow(imgs_lr[0].astype(int))\n",
    "  fig.savefig('images/%s/720/%d_lowres%d.png' % (dataset_name, epoch, 0))\n",
    "  plt.close()\n",
    "\n",
    "\n",
    "\n",
    "def train(epochs, generator=generator, discriminator=discriminator, disc_patch=disc_patch, vgg=vgg, combined=combined, batch_size=1, sample_interval=50):\n",
    "\n",
    "    start_time = datetime.datetime.now()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # ----------------------\n",
    "        #  Train Discriminator\n",
    "        # ----------------------\n",
    "\n",
    "        # Sample images and their conditioning counterparts\n",
    "        imgs_hr, imgs_lr = load_data()\n",
    "\n",
    "\n",
    "        # From low res. image generate high res. version\n",
    "\n",
    "        fake_hr = generator.predict(imgs_lr)\n",
    "\n",
    "        valid = np.ones((batch_size,) + disc_patch)\n",
    "        fake = np.zeros((batch_size,) + disc_patch)\n",
    "\n",
    "        # Train the discriminators (original images = real / generated = Fake)\n",
    "        d_loss_real = discriminator.train_on_batch(imgs_hr, valid)\n",
    "        d_loss_fake = discriminator.train_on_batch(fake_hr, fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        #  Train Generator\n",
    "        # Sample images and their conditioning counterparts\n",
    "        imgs_hr, imgs_lr = load_data()\n",
    "\n",
    "        # The generators want the discriminators to label the generated images as real\n",
    "        valid = np.ones((batch_size,) + disc_patch)\n",
    "\n",
    "        # Extract ground truth image features using pre-trained VGG19 model\n",
    "        image_features = vgg.predict(imgs_hr)\n",
    "\n",
    "        # Train the generators\n",
    "        g_loss = combined.train_on_batch([imgs_lr, imgs_hr], [valid, image_features])\n",
    "        elapsed_time = datetime.datetime.now() - start_time\n",
    "        print (\"%d time: %s\" % (epoch, elapsed_time))\n",
    "\n",
    "        # save image at every other interval\n",
    "        if epoch % sample_interval == 0:\n",
    "            sample_images(epoch)\n",
    "\n",
    "\n",
    "train(epochs=3500, batch_size=1, sample_interval=50) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}